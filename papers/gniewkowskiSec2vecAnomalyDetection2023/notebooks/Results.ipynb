{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecab0348",
   "metadata": {},
   "source": [
    "##  Length of embedding vector on final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b1b77bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mateuszg/http2vec\n"
     ]
    }
   ],
   "source": [
    "cd /home/mateuszg/http2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6747039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5faba75aa22745d1a5e66f0d83138adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('MALICIOUSURL', 'UNSW-NB15', 'CSIC2010', 'ISCXU…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Dropdown, IntSlider\n",
    "import pandas as pd\n",
    "\n",
    "from http2vec.evaluation import metrics_generator\n",
    "from http2vec.evaluation import get_data\n",
    "from http2vec.evaluation import get_split\n",
    "from http2vec.evaluation import get_predictions\n",
    "\n",
    "\n",
    "language_models = [\"bow\", \"roberta\", \"fasttext\"]\n",
    "datasets = [\"MALICIOUSURL\", \"UNSW-NB15\", \"CSIC2010\", \"ISCXURL2016\"]\n",
    "\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=datasets),\n",
    "    classifier=Dropdown(options=[\"rf\", \"lr\", \"svc\", \"mlp\"]),\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010\",\n",
    "    classifier=\"lr\"\n",
    "):\n",
    "    for lm in language_models:\n",
    "        df = metrics_generator(\n",
    "            language_model=lm,\n",
    "            dataset=dataset,\n",
    "            classifier=classifier,\n",
    "        )\n",
    "        print(lm)\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b3ccc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d43d7240d3547afb4a6bbd751e86a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('MALICIOUSURL', 'UNSW-NB15', 'CSIC2010', 'ISCXU…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def metrics_generator_clust(language_model, dataset, classifier=\"kmeans\"):\n",
    "    \"\"\"Generate DataFrame with metrics.\n",
    "    Args:\n",
    "        language_model (str): roberta, bow\n",
    "        dataset (str): name of dateset like bow-CSIC2010\n",
    "    \n",
    "    Returns: DataFrame\n",
    "    \"\"\"\n",
    "    ms = []\n",
    "    lens = []\n",
    "\n",
    "    dataset = f\"{language_model}-{dataset}\"\n",
    "    for filename in os.listdir(\"data/clustering/\"):\n",
    "        length = filename.split(\"-\")[-1]\n",
    "        if filename.startswith(dataset) and length.isdigit():\n",
    "            length = int(length)\n",
    "            try:\n",
    "                with open(f\"data/clustering/{filename}/metrics.json\") as f:\n",
    "                    metrics = json.load(f)[classifier]\n",
    "            except Exception as e:\n",
    "                continue\n",
    "            ms.append(metrics)\n",
    "            lens.append(length)\n",
    "            \n",
    "    ms = pd.DataFrame(ms)\n",
    "    ms[\"length\"] = lens\n",
    "    ms = ms.sort_values(by=\"length\")\n",
    "    ms.style.set_caption(dataset)\n",
    "    return ms\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=datasets),\n",
    "    classifier=Dropdown(options=[\"kmeans\", \"ac\", \"dbscan\"]),\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010\",\n",
    "    classifier=\"kmeans\"\n",
    "):\n",
    "    for lm in language_models:\n",
    "        df = metrics_generator_clust(\n",
    "            language_model=lm,\n",
    "            dataset=dataset,\n",
    "            classifier=classifier,\n",
    "        )\n",
    "        print(lm)\n",
    "        display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88980135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ceaf90a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb9916cc231407aaf09021947c1aa37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('MALICIOUSURL', 'UNSW-NB15', 'CSIC2010', 'ISCXU…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tikzplotlib\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=datasets),\n",
    "    classifier=Dropdown(options=[\"rf\", \"lr\", \"svc\"]),\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010\",\n",
    "    classifier=\"lr\"\n",
    "):\n",
    "    ax = None\n",
    "    f1s_avg = []\n",
    "    for lm in language_models:\n",
    "        df = metrics_generator(language_model=lm, dataset=dataset, classifier=classifier)\n",
    "        f1s_avg.append([df[\"f1\"].min(), df[\"f1\"].mean(), df[\"f1\"].max()])\n",
    "        ax = df.plot(x=\"length\", y=\"f1\", kind=\"scatter\", title=dataset, ax=ax)\n",
    "        df.plot.line(x=\"length\", y=\"f1\", ax=ax)\n",
    "    plt.legend(language_models)\n",
    "    #tikzplotlib.clean_figure()\n",
    "    tikzplotlib.save(f'{dataset}-lr-length.tex')\n",
    "    #plt.savefig(f'{dataset}-lr-length.pgf', backend='pgf')\n",
    "    display(pd.DataFrame(f1s_avg, index=language_models, columns=[\"min F1\", \"mean F1\", \"max F1\"]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57e6ab0",
   "metadata": {},
   "source": [
    "# Two-way table (full truth table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54f90e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa199331bed4144b6dec17c1b885f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('MALICIOUSURL', 'UNSW-NB15', 'CSIC2010', 'ISCXU…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=datasets),\n",
    "    lm=Dropdown(options=language_models),\n",
    "    size=Dropdown(options=[96, 192, 384, 768, 1536, 3072]),\n",
    "    classifier=Dropdown(options=[\"rf\", \"lr\", \"svc\"]),\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010\",\n",
    "    lm=\"bow\",\n",
    "    size=96,\n",
    "    classifier=\"lr\"\n",
    "):\n",
    "    data = get_data(dataset)\n",
    "    data.index = data[\"id\"].astype(str)\n",
    "    train_ids, test_ids = get_split(dataset=dataset, language_model=lm, size=size)\n",
    "    predictions = get_predictions(dataset=dataset, language_model=lm, size=size, classifier=classifier)\n",
    "    \n",
    "    data = data.loc[test_ids]\n",
    "    if (data[\"attack_cat\"] == \"\").all():\n",
    "        data[\"attack_cat\"] = data[\"label\"]\n",
    "    \n",
    "    predictions = pd.DataFrame(predictions.items(), columns=[\"index\", \"pred\"])\n",
    "    predictions.index = predictions[\"index\"]\n",
    "    predictions.drop([\"index\"], axis=1, inplace=True)\n",
    "    f1 = f1_score(data[\"label\"], predictions, pos_label=\"anomaly\")\n",
    "    print(\"F1-score: \", f1)\n",
    "    \n",
    "    data = pd.merge(predictions, data[\"attack_cat\"], left_index=True, right_index=True)\n",
    "    display(pd.crosstab(data.pred, data.attack_cat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
