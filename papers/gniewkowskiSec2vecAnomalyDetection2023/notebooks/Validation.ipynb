{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd83ce77",
   "metadata": {},
   "source": [
    "#  Validation between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "925c32d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mateuszg/http2vec\n"
     ]
    }
   ],
   "source": [
    "cd ~/http2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138bd7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from http2vec.evaluation import *\n",
    "\n",
    "\n",
    "sizes=[96, 192, 384, 768, 1536, 3072]\n",
    "language_models = [\"bow\", \"roberta\", \"fasttext\"]\n",
    "datasets = [\"MALICIOUSURL\", \"UNSW-NB15\", \"CSIC2010\", \"ISCXURL2016\"]\n",
    "\n",
    "def load_crossvalidation(\n",
    "    language_model,\n",
    "    dataset,\n",
    "    size,\n",
    "    against_dataset\n",
    "):\n",
    "    path = f\"data/cross-validation/{language_model}-{dataset}-{size}-{against_dataset}/metrics.json\"\n",
    "    with open(path) as f:\n",
    "        f1 = json.load(f)[\"f1\"]\n",
    "    return f1\n",
    "\n",
    "dataset = \"CSIC2010\"\n",
    "a_dataset = \"UNSW-NB15\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae2d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tikzplotlib\n",
    "plt.style.use(\"ggplot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da50ec49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098afadd463746728d63ae801fe81030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('CSIC2010->UNSW-NB15', 'MALICIOUSURL->ISCXURL20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Dropdown, IntSlider\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=[\n",
    "        \"CSIC2010->UNSW-NB15\",\n",
    "        \"MALICIOUSURL->ISCXURL2016\",\n",
    "    ])\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010->UNSW-NB15\"\n",
    "):\n",
    "    dataset, a_dataset = dataset.split(\"->\")\n",
    "    f1s = {size: load_crossvalidation(\"bow\", dataset, size, a_dataset) for size in sizes}\n",
    "    df = pd.DataFrame(f1s.items(), columns=[\"length\", \"BoW\"])\n",
    "    \n",
    "    f1s = {size: load_crossvalidation(\"fasttext\", dataset, size, a_dataset) for size in sizes}\n",
    "    df = df.merge(pd.DataFrame(f1s.items(), columns=[\"length\", \"fastText\"]), on=\"length\")\n",
    "    \n",
    "    f1s = {size: load_crossvalidation(\"roberta\", dataset, size, a_dataset) for size in sizes}\n",
    "    df = df.merge(pd.DataFrame(f1s.items(), columns=[\"length\", \"RoBERTa\"]), on=\"length\")\n",
    "\n",
    "    display(df)\n",
    "    \n",
    "    ax = None\n",
    " \n",
    "    ax = df.plot(x=\"length\", y=\"BoW\", kind=\"scatter\", title=dataset, ax=ax)\n",
    "    df.plot.line(x=\"length\", y=\"BoW\", ax=ax)   \n",
    "    \n",
    "    df.plot(x=\"length\", y=\"fastText\", kind=\"scatter\", title=dataset, ax=ax)\n",
    "    df.plot.line(x=\"length\", y=\"fastText\", ax=ax) \n",
    "    \n",
    "    df.plot(x=\"length\", y=\"RoBERTa\", kind=\"scatter\", title=dataset, ax=ax)\n",
    "    df.plot.line(x=\"length\", y=\"RoBERTa\", ax=ax)   \n",
    "    \n",
    "    ax.legend([\"BoW\", \"fastText\", \"RoBERTa\"])\n",
    "    ax.set_title(f'{dataset}->{a_dataset}')\n",
    "    ax.set_xlabel(\"length\")\n",
    "    ax.set_ylabel(\"F1\")\n",
    "    \n",
    "    tikzplotlib.save(f'{dataset}->{a_dataset}.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c78a54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1082dc0ed74894b150430bc7088459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='lm', options=('bow', 'roberta', 'fasttext'), value='bow'), Output(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import Dropdown, IntSlider\n",
    "\n",
    "@widgets.interact(\n",
    "    lm=Dropdown(options=[\"bow\", \"roberta\", \"fasttext\"]),\n",
    ")\n",
    "def update(\n",
    "    lm=\"bow\",\n",
    "):\n",
    "    \n",
    "    f1s = {size: load_crossvalidation(lm, dataset, size, a_dataset) for size in sizes}\n",
    "    df = metrics_generator(language_model=lm, dataset=dataset, classifier=\"rf\")[[\"f1\", \"length\"]]\n",
    "    df = pd.DataFrame(f1s.items(), columns=[\"length\", \"f1-cross\"]).merge(df, on=\"length\")\n",
    "    display(df)\n",
    "    \n",
    "    ax = None\n",
    " \n",
    "    ax = df.plot(x=\"length\", y=\"f1\", kind=\"scatter\", title=dataset, ax=ax)\n",
    "    df.plot.line(x=\"length\", y=\"f1\", ax=ax)\n",
    "    df.plot.line(x=\"length\", y=\"f1-cross\", ax=ax)    \n",
    "    ax.legend([\"f1\", \"f1-cross\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8770fb61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b3d1d8a7944880a642cb796c43328f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=('CSIC2010->UNSW-NB15', 'MALICIOUSURL->ISCXURL20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "def get_predictions_against(dataset, language_model, size, against_dataset):\n",
    "    exp = f\"{language_model}-{dataset}-{size}-{against_dataset}\"\n",
    "    path = f\"data/cross-validation/{exp}/saved/predictions-cross.json\"\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "\n",
    "@widgets.interact(\n",
    "    dataset=Dropdown(options=[\n",
    "        \"CSIC2010->UNSW-NB15\",\n",
    "        \"MALICIOUSURL->ISCXURL2016\",\n",
    "    ]),\n",
    "    lm=Dropdown(options=language_models),\n",
    "    size=Dropdown(options=[96, 192, 384, 768, 1536, 3072]),\n",
    ")\n",
    "def update(\n",
    "    dataset=\"CSIC2010->UNSW-NB15\",\n",
    "    lm=\"bow\",\n",
    "    size=96, \n",
    "):\n",
    "    \n",
    "    dataset, against_dataset = dataset.split(\"->\")\n",
    "    classifier=\"rf\"\n",
    "    data = get_data(against_dataset)\n",
    "    data.index = data[\"id\"].astype(str)\n",
    "    train_ids, test_ids = get_split(dataset=against_dataset, language_model=lm, size=size)\n",
    "    predictions = get_predictions(dataset=against_dataset, language_model=lm, size=size, classifier=classifier)\n",
    "    \n",
    "    data = data.loc[test_ids]\n",
    "    if (data[\"attack_cat\"] == \"\").all():\n",
    "        data[\"attack_cat\"] = data[\"label\"]\n",
    "    \n",
    "    predictions = pd.DataFrame(predictions.items(), columns=[\"index\", \"pred\"])\n",
    "    predictions.index = predictions[\"index\"]\n",
    "    predictions.drop([\"index\"], axis=1, inplace=True)\n",
    "    \n",
    "    \n",
    "    predictions2 = get_predictions_against(\n",
    "        dataset=dataset,\n",
    "        language_model=lm,\n",
    "        size=size,\n",
    "        against_dataset=against_dataset\n",
    "    )\n",
    "    predictions2 = pd.DataFrame(predictions2.items(), columns=[\"index\", \"pred_cross\"])\n",
    "    predictions2.index = predictions2[\"index\"]\n",
    "    predictions2.drop([\"index\"], axis=1, inplace=True)\n",
    "    \n",
    "    f1 = f1_score(data[\"label\"], predictions, pos_label=\"anomaly\")\n",
    "    f1_cross = f1_score(data[\"label\"], predictions2, pos_label=\"anomaly\")\n",
    "    \n",
    "    data = pd.merge(predictions, data[\"attack_cat\"], left_index=True, right_index=True)\n",
    "    data = pd.merge(predictions2, data, left_index=True, right_index=True)\n",
    "    \n",
    "    print(\"Original dataset results, F1:\", f1)\n",
    "    display(pd.crosstab(data.pred, data.attack_cat))\n",
    "    \n",
    "\n",
    "    print(\"Crossvalidation, F1\", f1_cross)\n",
    "\n",
    "    display(pd.crosstab(predictions2.pred_cross, data.attack_cat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
