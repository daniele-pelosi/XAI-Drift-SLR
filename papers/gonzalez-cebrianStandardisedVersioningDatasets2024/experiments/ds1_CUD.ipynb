{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data set 1<br>\n","The data set 1 is obtained from the UCI repository. It contains information from sensors and has been used for time-series prediction. This data set contains two subsets. The first, captured during 2011 March, with 2764 instants (≈28 days), and the second, captured during 2011 June, with 1373 instants (≈14 days).  In total, 4136 time instants are available. The data from March will be used as the PS, and the data from June will be added by batches of different size.<br>\n","## Preliminaries<br>\n","Import and load the uses Python packages and modules:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys\n","import os\n","# Add the parent directory to sys.path\n","parent_directory = os.path.abspath(os.path.join(os.getcwd(), '../main/'))\n","sys.path.insert(0, parent_directory)\n","import pandas as pd\n","import numpy as np\n","import sim_experiments as smexp_dyn\n","from datetime import date"]},{"cell_type":"markdown","metadata":{},"source":["Load the data set and prepare it:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfps = pd.read_csv(\"../datasets/ds01-PS.txt\", sep=\" \")\n","dfps[\"1:Date\"] = pd.to_datetime(dfps[\"1:Date\"], format = '%d/%m/%Y')\n","dfps[\"DayMonth\"] = dfps[\"1:Date\"].dt.strftime('%m-%d')\n","dfps[\"MonthYear\"] = dfps[\"1:Date\"].dt.strftime('%m-%Y')\n","dfps.set_index([\"1:Date\", \"2:Time\"], inplace=True)\n","dfps = dfps.select_dtypes(include=[float, int]) # type: ignore\n","X_PS = dfps.iloc[:,:-1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfrev = pd.read_csv(\"../datasets/ds01-R.txt\", sep=\" \")\n","dfrev[\"1:Date\"] = pd.to_datetime(dfrev[\"1:Date\"], format = '%d/%m/%Y')\n","dfrev[\"DayMonth\"] = dfrev[\"1:Date\"].dt.strftime('%m-%d')\n","dfrev[\"MonthYear\"] = dfrev[\"1:Date\"].dt.strftime('%m-%Y')\n","dfrev.set_index([\"1:Date\", \"2:Time\"], inplace=True)\n","dfrev = dfrev.select_dtypes(include=[float, int]) # type: ignore\n","X_NEW = dfrev.iloc[:,:-1]"]},{"cell_type":"markdown","metadata":{},"source":["Exploratory analysis showing time series decomposigion as an additive model where each time instant ($x_i$) is the addition of a trend component ($T_i$), <br>\n","a seasonal component ($S_i$) and an error component ($E_i$)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["smexp_dyn.plot_time_components_div(pd.concat([X_PS, X_NEW]), X_PS.index,  X_NEW.index, 96, dsname=\"ds01\", xtxtsize=6, path_figs=\"../figures/\")"]},{"cell_type":"markdown","metadata":{},"source":["## Primary Source models<br>\n","Obtain the parameters for the reference batch of data. The function returns a dictionary *ps_dict* with the parameters to compute each one of the drift metrics according to a different ML model and the _indPS_ variable with the indices of the records used for the reference set."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import random\n","import tensorflow as tf\n","tf.random.set_seed(42) \n","np.random.seed(42)\n","random.seed(42)\n","print(\"Doing Primary Source Model -- \\n\" + \"N = \" + str(len(X_PS)) + \" (\" + str(np.round(len(X_PS)/(len(X_PS) + len(X_NEW))*100,2)) + \" %\" + \" of total dataset length)\")\n","ps_dict, ind_PS = smexp_dyn.get_PS_data(X_PS, resultspath = \"../results/ds01/\", dstitle = \"DS 01 PS\", PSfilename = \"ds01ps.pkl\",\n","                                        dopickle=False, pctge_PS=1, noisefactor = 0.1, mse_model_type=\"splines\", resultsfile=\"dyn-ds-01\")"]},{"cell_type":"markdown","metadata":{},"source":["### New versions<br>\n","When a new version of the dataset is generated, it will be compared to the information from the previous version in the following way:<br>\n","  * $d_{P}$: computes the cosine distance between loading matrices obtained for both data sets;<br>\n","  * $d_{E, PCA}$: computes the MSE obtained by reconstructing the new batch using the reference PCA model. This value is fed into a quadratic model fitted with the reference data set, which relates MSE values to levels of corruption artificially simulated by permuting entries from the reference set.<br>\n","  * $d_{E, AE}$: computes the MSE obtained by reconstructing the new batch using the reference AE model. This value is fed into a quadratic model fitted with the reference data set, which relates MSE values to levels of corruption artificially simulated by permuting entries from the reference set."]},{"cell_type":"markdown","metadata":{},"source":["## Creation events<br>\n","The following experiments use an initial subset as reference and add new batches of different size."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"  - Case 1: add rows of new set \\n\")\n","try:\n","    smexp_dyn.do_exp(X_NEW, ps_dict, resultspath = \"../results/ds01\", mod_pca = True, mod_ae = True, mode_der = \"add_batch\",\n","                     batchsize_pctges = [0.05, 0.1, 0.25, 0.5, 0.75, 1], dstitle=\"DS 01 batch addition\", kfolds=0, resultsfile=\"/dyn-ds-01-add\")\n","except Exception as e: print(e)"]},{"cell_type":"markdown","metadata":{},"source":["## Update events<br>"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"  - Case 2: transform columns ..\\n\")\n","try: \n","    smexp_dyn.do_exp(X_PS, ps_dict, resultspath = \"../results/ds01\", mode_der = \"trans_cols\",\n","                    tr_pctges = [0.05, 0.1, 0.3, 0.5, 0.7, 0.8, 1], dstitle=\"DS 01 cbrt scale\", batchsize_pctges=[1], kfolds=1,\n","                    modetr=\"cbrt\",resultsfile=\"/fixed-ds-01-trcols-cbrt\")\n","except Exception as e: print(e)"]},{"cell_type":"markdown","metadata":{},"source":["## Deletion events<br>\n","In the following cases, the reference set contains all the records and some of them are deleted in different ways: signals are down sampled, outliers are removed, etc."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"  - Case 3: remove rows decimate .. \\n\")\n","try:\n","    smexp_dyn.do_exp(X_PS, ps_dict, resultspath = \"../results/ds01\", mode_der = \"rem_rows_decimate\",\n","                    tr_pctges = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05], dstitle=\"DS 01 decimate\",\n","                    batchsize_pctges=[1], resultsfile=\"/fixed-ds-01-downsample\")\n","except Exception as e: print(e)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":2}
